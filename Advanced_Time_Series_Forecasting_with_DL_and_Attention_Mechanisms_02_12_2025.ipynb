{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fEJx_3aT-xP",
        "outputId": "67b05871-9c12-440c-9b20-9f2ce8b80ded"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device detected: cpu\n",
            "Data shapes: (2948, 60, 3) (392, 60, 3) (589, 60, 3)\n",
            "Epoch 1/20 Train=0.091157 Val=0.021755\n",
            "Saved best model.\n",
            "Epoch 2/20 Train=0.002796 Val=0.009757\n",
            "Saved best model.\n",
            "Epoch 3/20 Train=0.000925 Val=0.004215\n",
            "Saved best model.\n",
            "Epoch 4/20 Train=0.000479 Val=0.001802\n",
            "Saved best model.\n",
            "Epoch 5/20 Train=0.000400 Val=0.001180\n",
            "Saved best model.\n",
            "Epoch 6/20 Train=0.000405 Val=0.003327\n",
            "Epoch 7/20 Train=0.000376 Val=0.001794\n",
            "Epoch 8/20 Train=0.000355 Val=0.003610\n",
            "Epoch 9/20 Train=0.000388 Val=0.002965\n",
            "Epoch 10/20 Train=0.000403 Val=0.002246\n",
            "Epoch 11/20 Train=0.000372 Val=0.001326\n",
            "Epoch 12/20 Train=0.000376 Val=0.000703\n",
            "Saved best model.\n",
            "Epoch 13/20 Train=0.000329 Val=0.000790\n",
            "Epoch 14/20 Train=0.000309 Val=0.000623\n",
            "Saved best model.\n",
            "Epoch 15/20 Train=0.000343 Val=0.000873\n",
            "Epoch 16/20 Train=0.000387 Val=0.000653\n",
            "Epoch 17/20 Train=0.000338 Val=0.001061\n",
            "Epoch 18/20 Train=0.000312 Val=0.000572\n",
            "Saved best model.\n",
            "Epoch 19/20 Train=0.000299 Val=0.000756\n",
            "Epoch 20/20 Train=0.000370 Val=0.000516\n",
            "Saved best model.\n",
            "\n",
            "=== RESULTS ===\n",
            "LSTM-Attn RMSE: 5.251898286135229\n",
            "LSTM-Attn MAPE: 2.3954258\n",
            "Baseline RMSE: 32.116741760741064\n",
            "Baseline MAPE: 16.624595631970134\n",
            "\n",
            "All done! File: report.txt is ready to submit.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "all_in_one_project.py\n",
        "Fully working single-file implementation of:\n",
        "\"Advanced Time Series Forecasting with LSTM + Bahdanau Attention\"\n",
        "\n",
        "This version contains:\n",
        "✔ No syntax errors\n",
        "✔ Fully fixed baseline\n",
        "✔ All training + evaluation\n",
        "✔ report.txt auto generated\n",
        "✔ Works on CPU (Windows safe)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# Utility\n",
        "# -------------------------------------------------------\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# Generate synthetic data\n",
        "# -------------------------------------------------------\n",
        "def generate_multivariate_ts(length=4000, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    t = np.arange(length)\n",
        "    df = pd.DataFrame({'t': t})\n",
        "    df['series1'] = 0.05*t + 3*np.sin(2*np.pi*t/365) + np.random.normal(0,0.5,length)\n",
        "    df['series2'] = 1.5*np.sin(2*np.pi*t/7) + 0.5*np.cos(2*np.pi*t/30) + np.random.normal(0,0.3,length)\n",
        "    df['series3'] = 0.02*t + np.random.normal(0,0.2,length)\n",
        "    spikes = np.random.choice(length, size=int(length*0.01), replace=False)\n",
        "    df.loc[spikes,'series3'] += np.random.normal(3,1,len(spikes))\n",
        "    return df[['series1','series2','series3']]\n",
        "\n",
        "def create_windows(values, seq_len=60, pred_h=12):\n",
        "    X=[];Y=[]\n",
        "    for i in range(len(values)-seq_len-pred_h+1):\n",
        "        X.append(values[i:i+seq_len])\n",
        "        Y.append(values[i+seq_len:i+seq_len+pred_h, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "def get_splits(seq_len=60, pred_h=12):\n",
        "    df = generate_multivariate_ts()\n",
        "    X, Y = create_windows(df.values.astype(np.float32), seq_len, pred_h)\n",
        "    N=len(X)\n",
        "    test=int(N*0.15)\n",
        "    val=int(N*0.10)\n",
        "    train=N-test-val\n",
        "    return X[:train],Y[:train], X[train:train+val],Y[train:train+val], X[train+val:],Y[train+val:]\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# Scaling\n",
        "# -------------------------------------------------------\n",
        "class TimeSeriesScaler:\n",
        "    def __init__(self):\n",
        "        self.scalers = {}\n",
        "    def fit_transform(self,X):\n",
        "        N,L,F = X.shape\n",
        "        Xs=np.zeros_like(X)\n",
        "        for f in range(F):\n",
        "            sc=MinMaxScaler((-1,1))\n",
        "            flat=X[:,:,f].reshape(-1,1)\n",
        "            sc.fit(flat)\n",
        "            Xs[:,:,f]=sc.transform(flat).reshape(N,L)\n",
        "            self.scalers[f]=sc\n",
        "        return Xs\n",
        "    def transform(self,X):\n",
        "        N,L,F=X.shape\n",
        "        Xs=np.zeros_like(X)\n",
        "        for f in range(F):\n",
        "            sc=self.scalers[f]\n",
        "            Xs[:,:,f]=sc.transform(X[:,:,f].reshape(-1,1)).reshape(N,L)\n",
        "        return Xs\n",
        "    def transform_targets(self,y):\n",
        "        sc=self.scalers[0]\n",
        "        return sc.transform(y.reshape(-1,1)).reshape(len(y),-1)\n",
        "    def inverse_transform_target(self,y_s):\n",
        "        sc=self.scalers[0]\n",
        "        return sc.inverse_transform(y_s.reshape(-1,1)).reshape(len(y_s),-1)\n",
        "\n",
        "class SeqDataset(Dataset):\n",
        "    def __init__(self,X,Y):\n",
        "        self.X=X.astype('float32')\n",
        "        self.Y=Y.astype('float32')\n",
        "    def __len__(self):return len(self.X)\n",
        "    def __getitem__(self,i):return self.X[i],self.Y[i]\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# LSTM + Attention\n",
        "# -------------------------------------------------------\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,input_dim,hid):\n",
        "        super().__init__()\n",
        "        self.lstm=nn.LSTM(input_dim,hid,batch_first=True)\n",
        "    def forward(self,src):\n",
        "        out,(h,c)=self.lstm(src)\n",
        "        return out,h[-1],c[-1]\n",
        "\n",
        "class Bahdanau(nn.Module):\n",
        "    def __init__(self,enc_hid,dec_hid):\n",
        "        super().__init__()\n",
        "        self.W=nn.Linear(enc_hid+dec_hid,dec_hid)\n",
        "        self.v=nn.Linear(dec_hid,1,bias=False)\n",
        "    def forward(self,h_t,enc_out):\n",
        "        batch,src_len,_=enc_out.shape\n",
        "        h_rep=h_t.unsqueeze(1).repeat(1,src_len,1)\n",
        "        energy=torch.tanh(self.W(torch.cat([h_rep,enc_out],dim=2)))\n",
        "        att=self.v(energy).squeeze(2)\n",
        "        return F.softmax(att,dim=1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,enc_hid,dec_hid):\n",
        "        super().__init__()\n",
        "        self.att=Bahdanau(enc_hid,dec_hid)\n",
        "        self.lcell=nn.LSTMCell(enc_hid+1,dec_hid)\n",
        "        self.fc=nn.Linear(dec_hid,1)\n",
        "    def forward(self,prev_y,h,c,enc_out):\n",
        "        att=self.att(h,enc_out)\n",
        "        ctx=torch.bmm(att.unsqueeze(1),enc_out).squeeze(1)\n",
        "        inp=torch.cat([prev_y,ctx],dim=1)\n",
        "        h,c=self.lcell(inp,(h,c))\n",
        "        out=self.fc(h)\n",
        "        return out,h,c,att\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,input_dim,enc_hid,dec_hid,device):\n",
        "        super().__init__()\n",
        "        self.enc=Encoder(input_dim,enc_hid)\n",
        "        self.dec=Decoder(enc_hid,dec_hid)\n",
        "        self.device=device\n",
        "    def forward(self,x,horizon,tf_ratio,targets=None):\n",
        "        enc_out,h,c=self.enc(x)\n",
        "        batch=x.size(0)\n",
        "        prev_y=torch.zeros(batch,1,device=self.device)\n",
        "        outs=[];atts=[]\n",
        "        for t in range(horizon):\n",
        "            out,h,c,att=self.dec(prev_y,h,c,enc_out)\n",
        "            outs.append(out)\n",
        "            atts.append(att.unsqueeze(1))\n",
        "            if targets is not None and random.random()<tf_ratio:\n",
        "                prev_y=targets[:,t].unsqueeze(1)\n",
        "            else:\n",
        "                prev_y=out.detach()\n",
        "        return torch.cat(outs,1).squeeze(-1), torch.cat(atts,1)\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# FIXED Baseline (No errors)\n",
        "# -------------------------------------------------------\n",
        "def baseline_sarima_like(X_train,Y_train,X_test,horizon):\n",
        "    train_series = X_train[:, -1, 0]\n",
        "    try:\n",
        "        from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "        model=SARIMAX(train_series,order=(1,1,1),seasonal_order=(1,1,1,12),\n",
        "                      enforce_stationarity=False,enforce_invertibility=False)\n",
        "        res=model.fit(disp=False)\n",
        "        fc=res.forecast(horizon)\n",
        "        return np.tile(fc.reshape(1,-1),(len(X_test),1))\n",
        "    except Exception as e:\n",
        "        print(\"SARIMA failed → using naive baseline.\",e)\n",
        "        last=train_series[-1]\n",
        "        return np.tile(last,(len(X_test),horizon))\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# Metrics\n",
        "# -------------------------------------------------------\n",
        "def rmse(a,b):return np.sqrt(mean_squared_error(a.reshape(-1),b.reshape(-1)))\n",
        "def mape(a,b):\n",
        "    denom=np.maximum(np.abs(a),1e-6)\n",
        "    return np.mean(np.abs((a-b)/denom))*100\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# MAIN\n",
        "# -------------------------------------------------------\n",
        "def main():\n",
        "    DEVICE=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Device detected:\",DEVICE)\n",
        "\n",
        "    os.makedirs(\"models\",exist_ok=True)\n",
        "    os.makedirs(\"outputs\",exist_ok=True)\n",
        "\n",
        "    SEQ=60;H=12;ENC=64;DEC=64;BATCH=64;EPOCHS=20;LR=1e-3\n",
        "\n",
        "    # LOAD DATA\n",
        "    X_train,Y_train,X_val,Y_val,X_test,Y_test = get_splits(SEQ,H)\n",
        "    print(\"Data shapes:\",X_train.shape,X_val.shape,X_test.shape)\n",
        "\n",
        "    # SCALE\n",
        "    sc=TimeSeriesScaler()\n",
        "    X_train_s=sc.fit_transform(X_train)\n",
        "    X_val_s=sc.transform(X_val)\n",
        "    X_test_s=sc.transform(X_test)\n",
        "    Y_train_s=sc.transform_targets(Y_train)\n",
        "    Y_val_s=sc.transform_targets(Y_val)\n",
        "    Y_test_s=sc.transform_targets(Y_test)\n",
        "\n",
        "    train_dl=DataLoader(SeqDataset(X_train_s,Y_train_s),batch_size=BATCH,shuffle=True)\n",
        "    val_dl=DataLoader(SeqDataset(X_val_s,Y_val_s),batch_size=BATCH)\n",
        "    test_dl=DataLoader(SeqDataset(X_test_s,Y_test_s),batch_size=BATCH)\n",
        "\n",
        "    # MODEL\n",
        "    model=Seq2Seq(3,ENC,DEC,DEVICE).to(DEVICE)\n",
        "    opt=optim.Adam(model.parameters(),lr=LR)\n",
        "    lossf=nn.MSELoss()\n",
        "\n",
        "    best=float(\"inf\")\n",
        "\n",
        "    # TRAIN\n",
        "    for ep in range(1,EPOCHS+1):\n",
        "        model.train()\n",
        "        total=0\n",
        "        for xb,yb in train_dl:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            opt.zero_grad()\n",
        "            out,_=model(xb,H,0.5,yb)\n",
        "            loss=lossf(out,yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            total+=loss.item()*xb.size(0)\n",
        "        tr_loss=total/len(X_train_s)\n",
        "\n",
        "        # VAL\n",
        "        model.eval()\n",
        "        v=0\n",
        "        with torch.no_grad():\n",
        "            for xb,yb in val_dl:\n",
        "                xb,yb=xb.to(DEVICE),yb.to(DEVICE)\n",
        "                out,_=model(xb,H,0.0)\n",
        "                v+=lossf(out,yb).item()*xb.size(0)\n",
        "        v_loss=v/len(X_val_s)\n",
        "\n",
        "        print(f\"Epoch {ep}/{EPOCHS} Train={tr_loss:.6f} Val={v_loss:.6f}\")\n",
        "        if v_loss<best:\n",
        "            best=v_loss\n",
        "            torch.save(model.state_dict(),\"models/best_seq2seq.pt\")\n",
        "            print(\"Saved best model.\")\n",
        "\n",
        "    # LOAD BEST\n",
        "    model.load_state_dict(torch.load(\"models/best_seq2seq.pt\",map_location=DEVICE))\n",
        "    model.eval()\n",
        "\n",
        "    # TEST PRED\n",
        "    preds_s=[];atts=[]\n",
        "    with torch.no_grad():\n",
        "        for xb,yb in test_dl:\n",
        "            xb=xb.to(DEVICE)\n",
        "            out,att=model(xb,H,0.0)\n",
        "            preds_s.append(out.cpu().numpy());atts.append(att.cpu().numpy())\n",
        "    preds_s=np.vstack(preds_s)\n",
        "    atts=np.vstack(atts)\n",
        "\n",
        "    preds=sc.inverse_transform_target(preds_s)\n",
        "    true=sc.inverse_transform_target(Y_test_s)\n",
        "\n",
        "    # BASELINE\n",
        "    base=baseline_sarima_like(X_train,Y_train,X_test,H)\n",
        "\n",
        "    # METRICS\n",
        "    rm=rmse(true,preds)\n",
        "    mp=mape(true,preds)\n",
        "    br=rmse(true,base)\n",
        "    bm=mape(true,base)\n",
        "\n",
        "    print(\"\\n=== RESULTS ===\")\n",
        "    print(\"LSTM-Attn RMSE:\",rm)\n",
        "    print(\"LSTM-Attn MAPE:\",mp)\n",
        "    print(\"Baseline RMSE:\",br)\n",
        "    print(\"Baseline MAPE:\",bm)\n",
        "\n",
        "    # SAVE SUMMARY\n",
        "    with open(\"outputs/summary.txt\",\"w\") as f:\n",
        "        f.write(f\"LSTM RMSE: {rm}\\n\")\n",
        "        f.write(f\"LSTM MAPE: {mp}\\n\")\n",
        "        f.write(f\"Baseline RMSE: {br}\\n\")\n",
        "        f.write(f\"Baseline MAPE: {bm}\\n\")\n",
        "\n",
        "    # PLOTS\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(true[0],label=\"True\")\n",
        "    plt.plot(preds[0],label=\"Pred\")\n",
        "    plt.legend()\n",
        "    plt.savefig(\"outputs/pred_sample.png\")\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.imshow(atts[0],aspect='auto')\n",
        "    plt.colorbar()\n",
        "    plt.savefig(\"outputs/attention_sample.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # REPORT\n",
        "    with open(\"report.txt\",\"w\") as r:\n",
        "        r.write(\"Advanced Time Series Forecasting with LSTM + Bahdanau Attention\\n\")\n",
        "        r.write(\"Author: Venkatesh Smart\\n\\n\")\n",
        "        r.write(f\"LSTM RMSE: {rm}\\n\")\n",
        "        r.write(f\"LSTM MAPE: {mp}\\n\")\n",
        "        r.write(f\"Baseline RMSE: {br}\\n\")\n",
        "        r.write(f\"Baseline MAPE: {bm}\\n\")\n",
        "        r.write(\"Plots saved in outputs/.\\n\")\n",
        "\n",
        "    print(\"\\nAll done! File: report.txt is ready to submit.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ]
}